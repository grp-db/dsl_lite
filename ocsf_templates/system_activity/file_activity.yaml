# OCSF Gold Mapping Template: file_activity
# Class UID: 1001 | Category: System Activity
#
# File System Activity events capture file operations (create, read, update, delete, etc.).

gold:
  # Note: clusterBy is supported in SSS (Spark Structured Streaming) mode but not in SDP mode (sinks don't support it atm)
  # For SDP mode, run ALTER TABLE after pipeline creation:
  #   ALTER TABLE <catalog>.<database>.file_activity CLUSTER BY (time, file.path)
  - name: file_activity
    input: <YOUR_SILVER_TABLE_NAME>
    # clusterBy: ["time", "file.path"]  # Only works in SSS mode (src/sss_gold.py)
    # filter: |
    #   event_type IN ('file_create', 'file_delete', 'file_modify', 'file_rename')
    fields:
      # Required OCSF fields
      - name: activity_id
        expr: # 1=Create, 2=Read, 3=Update, 4=Delete, 5=Rename, etc.
      - name: activity_name
        expr: # Activity name
      # Category & Class
      - name: category_name
        literal: System Activity
      - name: category_uid
        expr: CAST(1 AS INT)
      - name: class_name
        literal: File System Activity
      - name: class_uid
        expr: CAST(1001 AS INT)
      
      - name: severity_id
        expr: # 0-6
      - name: time
        from: # Event timestamp
      - name: type_uid
        expr: # 100101=Create, 100104=Delete, etc.
      - name: type_name
        expr: # 'File System Activity: Create/Delete'
      
      # File information
      - name: file.name
        expr: # File name
      - name: file.path
        expr: # Full file path
      - name: file.type
        expr: # File type/extension
      - name: file.type_id
        expr: # File type ID
      - name: file.size
        expr: # File size in bytes
      - name: file.uid
        expr: # File unique ID/inode
      
      # File hashes
      - name: file.hashes
        expr: # Array of hash objects with algorithm and value
      
      # Actor (user/process performing action)
      - name: actor.user.name
        expr: # Username
      - name: actor.user.uid
        expr: # User ID
      - name: actor.process.name
        expr: # Process name
      - name: actor.process.pid
        expr: # Process ID
      - name: actor.process.cmd_line
        expr: # Command line
      
      # Device
      - name: device.hostname
        expr: # Device hostname
      - name: device.ip
        expr: # Device IP
      - name: device.uid
        expr: # Device ID
      
      # Status
      - name: status_id
        expr: # 1=Success, 2=Failure
      - name: status
        expr: # Status description
      
      - name: access_mask
        expr: # TODO: Map to your source field

      - name: action
        expr: # TODO: Map to your source field

      - name: action_id
        expr: # TODO: Map to your source field

      - name: activity
        expr: # TODO: Map to your source field

      - name: component
        expr: # TODO: Map to your source field

      - name: disposition
        expr: # TODO: Map to your source field

      - name: disposition_id
        expr: # TODO: Map to your source field

      - name: enrichments
        expr: # TODO: Map to your source field (VARIANT/ARRAY)

      - name: file_diff
        expr: # TODO: Map to your source field

      - name: observables
        expr: # TODO: Map to your source field (VARIANT/ARRAY)

      - name: severity
        expr: # TODO: Map to your source field

      - name: status_code
        expr: # TODO: Map to your source field

      - name: status_detail
        expr: # TODO: Map to your source field

      - name: timezone_offset
        expr: # TODO: Map to your source field (timezone offset in minutes)

      - name: unmapped
        expr: # TODO: Map to your source field (VARIANT/ARRAY)
      # Metadata (OCSF Standard Fields)
      - name: metadata.version
        literal: "1.7.0"  # OCSF schema version
      - name: metadata.product.name
        literal: # Product name (e.g., "Zeek Conn", "Cisco IOS")
      - name: metadata.product.vendor_name
        literal: # Vendor name (e.g., "Zeek", "Cisco")
      - name: metadata.log_provider
        literal: # Log provider/source (e.g., "zeek", "cisco", "cloudflare")
      - name: metadata.log_name
        literal: # Log name/sourcetype (e.g., "conn", "ios", "gateway_dns")
      - name: metadata.log_format
        literal: # Log format (e.g., "JSON", "syslog", "CSV")
      - name: metadata.log_version
        literal: # Schema version format: "source@sourcetype:version@1.0" (e.g., "zeek@conn:version@1.0")
      - name: metadata.processed_time
        expr: CURRENT_TIMESTAMP()  # When processed by pipeline
      - name: metadata.logged_time
        from: time  # When the event was logged (REQUIRED: map to your time field)
      
      # Optional fields
      - name: message
        expr: # Description
      - name: raw_data
        from: # Original event

