# OCSF Gold Mapping Template: data_security_finding
# Class UID: 2003 | Category: Findings
#
# Data Security Finding events capture data security issues and anomalies.

gold:
  # Note: clusterBy is supported in SSS (Spark Structured Streaming) mode but not in SDP mode (sinks don't support it atm)
  # For SDP mode, run ALTER TABLE after pipeline creation:
  #   ALTER TABLE <catalog>.<database>.data_security_finding CLUSTER BY (time, finding_info.uid)
  - name: data_security_finding
    input: <YOUR_SILVER_TABLE_NAME>
    # clusterBy: ["time", "finding_info.uid"]  # Only works in SSS mode (src/sss_gold.py)
    fields:
      - name: activity_id
        expr: # 1=Create, 2=Update, 3=Close
      - name: activity_name
        expr: 
      # Category & Class
      - name: category_name
        literal: Findings
      - name: category_uid
        expr: CAST(2 AS INT)
      - name: class_name
        literal: Data Security Finding
      - name: class_uid
        expr: CAST(2006 AS INT)
      
      - name: severity_id
        expr: 
      - name: time
        from: 
      - name: finding_info.title
        expr: # Finding title
      - name: finding_info.desc
        expr: # Finding description
      - name: finding_info.uid
        expr: # Finding unique ID
      - name: finding_info.created_time
        expr: 
      - name: finding_info.first_seen_time
        expr: 
      - name: finding_info.last_seen_time
        expr: 
      - name: risk_level_id
        expr: # 1=Info, 2=Low, 3=Medium, 4=High, 5=Critical
      - name: risk_level
        expr: 
      - name: risk_score
        expr: # Numeric risk score
      - name: confidence_id
        expr: # Confidence level
      - name: confidence_score
        expr: 
      - name: database.name
        expr: # If database-related
      - name: database.uid
        expr: 
      - name: database.type
        expr: 
      - name: databucket.name
        expr: # If storage bucket-related
      - name: databucket.uid
        expr: 
      - name: databucket.is_public
        expr: 
      - name: databucket.is_encrypted
        expr: 
      - name: file.name
        expr: # If file-related
      - name: file.path
        expr: 
      - name: table.name
        expr: # If table-related
      - name: table.uid
        expr: 
      - name: status_id
        expr: # 1=New, 2=In Progress, 3=Suppressed, 4=Resolved
      - name: action
        expr: # TODO: Map to your source field

      - name: action_id
        expr: # TODO: Map to your source field

      - name: actor
        expr: # TODO: Map to your source field

      - name: api
        expr: # TODO: Map to your source field

      - name: cloud
        expr: # TODO: Map to your source field

      - name: confidence
        expr: # TODO: Map to your source field

      - name: device
        expr: # TODO: Map to your source field

      - name: disposition
        expr: # TODO: Map to your source field

      - name: disposition_id
        expr: # TODO: Map to your source field

      - name: dst_endpoint
        expr: # TODO: Map to your source field

      - name: end_time
        expr: # TODO: Map to your source field

      - name: enrichments
        expr: # TODO: Map to your source field (VARIANT/ARRAY)

      - name: impact
        expr: # TODO: Map to your source field

      - name: impact_id
        expr: # TODO: Map to your source field

      - name: impact_score
        expr: # TODO: Map to your source field

      - name: is_alert
        expr: # TODO: Map to your source field

      - name: message
        expr: # TODO: Map to your source field

      - name: observables
        expr: # TODO: Map to your source field (VARIANT/ARRAY)

      - name: risk_details
        expr: # TODO: Map to your source field

      - name: severity
        expr: # TODO: Map to your source field

      - name: src_endpoint
        expr: # TODO: Map to your source field

      - name: status
        expr: # TODO: Map to your source field

      - name: status_code
        expr: # TODO: Map to your source field

      - name: status_detail
        expr: # TODO: Map to your source field

      - name: timezone_offset
        expr: # TODO: Map to your source field (timezone offset in minutes)

      - name: type_name
        expr: # TODO: Map to your source field

      - name: unmapped
        expr: # TODO: Map to your source field (VARIANT/ARRAY)
      # Metadata (OCSF Standard Fields)
      - name: metadata.version
        literal: "1.7.0"  # OCSF schema version
      - name: metadata.product.name
        literal: # Product name (e.g., "Zeek Conn", "Cisco IOS")
      - name: metadata.product.vendor_name
        literal: # Vendor name (e.g., "Zeek", "Cisco")
      - name: metadata.log_provider
        literal: # Log provider/source (e.g., "zeek", "cisco", "cloudflare")
      - name: metadata.log_name
        literal: # Log name/sourcetype (e.g., "conn", "ios", "gateway_dns")
      - name: metadata.log_format
        literal: # Log format (e.g., "JSON", "syslog", "CSV")
      - name: metadata.log_version
        literal: # Schema version format: "source@sourcetype:version@1.0" (e.g., "zeek@conn:version@1.0")
      - name: metadata.processed_time
        expr: CURRENT_TIMESTAMP()  # When processed by pipeline
      - name: metadata.logged_time
        from: time  # When the event was logged (REQUIRED: map to your time field)
      # Raw data
      - name: raw_data
        from: 

